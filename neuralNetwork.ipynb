{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3개층으로 신경망으로 MNIST 데이터를 학습하는 코드\n",
    "\n",
    "import numpy as np\n",
    "# 시그모이드 함수 expit() 사용을 위해 scipy.special 불러오기\n",
    "import scipy.special\n",
    "# 행렬을 시각화하기 위한 라이브러리\n",
    "import matplotlib.pyplot\n",
    "# 시각화가 외부 윈도우가 아닌 현재의 노트북 내에서 보이도록 설정\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 신경망 클래스의 정의\n",
    "class neuralNetwork:\n",
    "    \n",
    "    # 신경망 초기화하기 - 입력, 은닉, 출력 노드의 수 설정\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        \n",
    "        # 입력, 은닉, 출력 계층의 노드 개수 설정\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "        \n",
    "        # 가중치 행렬 wid와 who\n",
    "        # 배열 내 가중치는 w_i_i로 표기. 노드 i에서 다음 계층의 노드 j로 여녈됨을 의미\n",
    "        # w11 w21\n",
    "        # w12 w22 등\n",
    "        self.wih = np.random.normal(0.0, pow(self.hnodes, -0.5), (self.hnodes, self.inodes))\n",
    "        self.who = np.random.normal(0.0, pow(self.onodes, -0.5), (self.onodes, self.hnodes))\n",
    "        \n",
    "        # 학습률\n",
    "        self.lr = learningrate\n",
    "        \n",
    "        # 활성화 함수로는 시그모이드 함수를 이용\n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    # 신경망 학습시키기 - 학습 데이터들을 통해 학습하고 이에 따라 가중치를 업데이트\n",
    "    def train(self, inputs_list, targets_list):\n",
    "        \n",
    "        # 입력 리스트를 2차원의 행렬로 변환\n",
    "        inputs = np.array(inputs_list, ndmin=2).T\n",
    "        targets = np.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        # 은닉 계층으로 들어오는 신호를 계산\n",
    "        hidden_inputs = np.dot(self.wih, inputs)\n",
    "        # 은닉 계층에서 나가는 신호를 계산\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "\n",
    "        # 최종 출력 계층으로 들어오는 신호를 계산\n",
    "        final_inputs = np.dot(self.who, hidden_outputs)\n",
    "        # 최종 출력 계층에서 나가는 신호를 계산\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        # 출력 계층의 오차는 (실제값 - 계산값)\n",
    "        output_errors = targets - final_outputs\n",
    "        # 은닉 계층의 오차는 가중치에 의해 나뉜 출력 계층의 오차들을 재조합해 계산\n",
    "        hidden_errors = np.dot(self.who.T, output_errors)\n",
    "        \n",
    "        # 은닉 계층과 출력 계층 간의 가중치 업데이트\n",
    "        self.who += self.lr * np.dot((output_errors * final_outputs * (1.0 - final_outputs)), np.transpose(hidden_outputs))\n",
    "        \n",
    "        # 입력 계층과 은닉 계층 간의 가중치 업데이트\n",
    "        self.wih += self.lr * np.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), np.transpose(inputs))\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    # 신경망에 질의하기 - 입력을 받아 연산한 후 출력 노드에서 답을 전달\n",
    "    def query(self, inputs_list):\n",
    "        \n",
    "        # 입력 리스트를 2차원 행렬로 변환\n",
    "        inputs = np.array(inputs_list, ndmin=2).T\n",
    "        \n",
    "        # 은닉 계층으로 들어오는 신호를 계산\n",
    "        hidden_inputs = np.dot(self.wih, inputs)\n",
    "        # 은닉 계층에서 나가는 신호를 계산\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        # 최종 출력 계층으로 들어오는 신호를 계산\n",
    "        final_inputs = np.dot(self.who, hidden_outputs)\n",
    "        # 최종 출력 계층에서 나가는 신호를 계산\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        return final_outputs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 입력, 은닉, 출력 노드의 수\n",
    "input_nodes = 784\n",
    "hidden_nodes = 100\n",
    "output_nodes = 10\n",
    "\n",
    "# 학습률은 0.3으로 정의\n",
    "learning_rate = 0.3\n",
    "\n",
    "# 신경망의 인스턴스를 생성\n",
    "n = neuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MNIST 학습 데이터인 csv 파일을 리스트로 불러오기\n",
    "training_data_file = open('./mnist_train_100.csv','r')\n",
    "training_data_list = training_data_file.readlines()\n",
    "training_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x118316630>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114f040b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_values = training_data_list[0].split(',')\n",
    "image_array = np.asfarray(all_values[1:]).reshape((28,28))\n",
    "matplotlib.pyplot.imshow(image_array, cmap='Greys', interpolation='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1185eaf28>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1182dd6d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_values = training_data_list[1].split(',')\n",
    "image_array = np.asfarray(all_values[1:]).reshape((28,28))\n",
    "matplotlib.pyplot.imshow(image_array, cmap='Greys', interpolation='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 신경망 학습시키기\n",
    "\n",
    "# 주기(epoch)란 학습 데이터가 학습을 위해 사용되는 횟수를 의미\n",
    "epochs = 2\n",
    "\n",
    "for e in range(epochs): \n",
    "    # 학습 데이터 모음 내의 모든 레코드 탐색\n",
    "    for record in training_data_list:\n",
    "        # 레코드를 쉼표에 의해 분리\n",
    "        all_values = record.split(',')\n",
    "        # 입력 값의 범위와 값 조정\n",
    "        inputs = (np.asfarray(all_values[1:])/ 255.0 * 0.99) + 0.01\n",
    "        # 결과값 생성 (실제 값인 0.99 외에는 모두 0.01)\n",
    "        targets = np.zeros(output_nodes) + 0.01\n",
    "        # all_values[0]은 이 레코드에 대한 결과값\n",
    "        targets[int(all_values[0])] = 0.99\n",
    "        n.train(inputs, targets)\n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onodes = 10\n",
    "targets = np.zeros(onodes) + 0.01\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "targets[int(all_values[0])] = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01,  0.99,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaled_input = np.asfarray(all_values[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,   85.,  255.,  103.,    1.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,  205.,  253.,  253.,   30.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,  205.,  253.,  253.,   30.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,   44.,  233.,  253.,  244.,\n",
       "         27.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,  135.,  253.,  253.,\n",
       "        100.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,  153.,  253.,\n",
       "        240.,   76.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,   12.,  208.,\n",
       "        253.,  166.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,   69.,\n",
       "        253.,  253.,  142.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,   14.,\n",
       "        110.,  253.,  235.,   33.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         63.,  223.,  235.,  130.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,  186.,  253.,  235.,   37.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,   17.,  145.,  253.,  231.,   35.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,   69.,  220.,  231.,  123.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,   18.,  205.,  253.,  176.,   27.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,   17.,  125.,  253.,  185.,   39.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,   71.,  214.,  231.,   41.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,  167.,  253.,  225.,   33.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,   72.,  205.,  207.,   14.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,   30.,  249.,  233.,   49.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,   32.,  253.,   89.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaled_input = (np.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.34      ,  1.        ,  0.40988235,  0.01388235,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.80588235,\n",
       "        0.99223529,  0.99223529,  0.12647059,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.80588235,  0.99223529,  0.99223529,\n",
       "        0.12647059,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.18082353,\n",
       "        0.91458824,  0.99223529,  0.95729412,  0.11482353,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.53411765,  0.99223529,  0.99223529,\n",
       "        0.39823529,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.604     ,  0.99223529,  0.94176471,  0.30505882,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.05658824,  0.81752941,  0.99223529,\n",
       "        0.65447059,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.27788235,  0.99223529,  0.99223529,  0.56129412,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.06435294,  0.43705882,  0.99223529,\n",
       "        0.92235294,  0.13811765,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.25458824,  0.87576471,  0.92235294,  0.51470588,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.73211765,  0.99223529,\n",
       "        0.92235294,  0.15364706,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.076     ,  0.57294118,  0.99223529,  0.90682353,  0.14588235,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.27788235,  0.86411765,\n",
       "        0.90682353,  0.48752941,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.07988235,  0.80588235,  0.99223529,  0.69329412,  0.11482353,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.076     ,  0.49529412,  0.99223529,\n",
       "        0.72823529,  0.16141176,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.28564706,  0.84082353,  0.90682353,  0.16917647,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.65835294,  0.99223529,\n",
       "        0.88352941,  0.13811765,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.28952941,  0.80588235,  0.81364706,  0.06435294,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.12647059,  0.97670588,  0.91458824,\n",
       "        0.20023529,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.13423529,  0.99223529,  0.35552941,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ,  0.01      ,\n",
       "        0.01      ,  0.01      ,  0.01      ,  0.01      ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 테스트 데이터 불러오기\n",
    "test_data_file = open('./mnist_test_10.csv','r')\n",
    "test_data_list = test_data_file.readlines()\n",
    "test_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['7', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '84', '185', '159', '151', '60', '36', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '222', '254', '254', '254', '254', '241', '198', '198', '198', '198', '198', '198', '198', '198', '170', '52', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '67', '114', '72', '114', '163', '227', '254', '225', '254', '254', '254', '250', '229', '254', '254', '140', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '17', '66', '14', '67', '67', '67', '59', '21', '236', '254', '106', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '83', '253', '209', '18', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '22', '233', '255', '83', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '129', '254', '238', '44', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '59', '249', '254', '62', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '133', '254', '187', '5', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '9', '205', '248', '58', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '126', '254', '182', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '75', '251', '240', '57', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '19', '221', '254', '166', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '3', '203', '254', '219', '35', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '38', '254', '254', '77', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '31', '224', '254', '115', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '133', '254', '254', '52', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '61', '242', '254', '254', '52', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '121', '254', '254', '219', '40', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '121', '254', '207', '18', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0\\n']\n"
     ]
    }
   ],
   "source": [
    "# 첫번째 테스트 데이터 불러오기\n",
    "all_values = test_data_list[0].split(',')\n",
    "print(all_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "# 첫번째 테스트 데이터의 라벨만 보기\n",
    "print(all_values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1187eb550>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxloGViyOX1gAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1182d7080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_array = np.asfarray(all_values[1:]).reshape((28,28))\n",
    "matplotlib.pyplot.imshow(image_array, cmap='Greys', interpolation='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04092069],\n",
       "       [ 0.01481431],\n",
       "       [ 0.05674127],\n",
       "       [ 0.0553971 ],\n",
       "       [ 0.05172703],\n",
       "       [ 0.01225153],\n",
       "       [ 0.00219535],\n",
       "       [ 0.89449118],\n",
       "       [ 0.01609004],\n",
       "       [ 0.01241407]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.query((np.asfarray(all_values[1:])/255.0 * 0.99) + 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 신경망 테스트\n",
    "\n",
    "# 신경망의 성능의 지표가 되는 성적표를 아무 값도 가지지 않도록 초기화\n",
    "scorecard = []\n",
    "\n",
    "# 테스트 데이터 모음 내의 모든 레코드 탑색\n",
    "\n",
    "for record in test_data_list:\n",
    "    # 레코드를 쉼표에 의해 분리\n",
    "    all_values = record.split(',')\n",
    "    # 정답은 첫 번째 값\n",
    "    correct_label = int(all_values[0])\n",
    "    # print(\"correct lable\", correct_label)\n",
    "    # 입력 값의 범위와 값 조정\n",
    "    inputs = (np.asfarray(all_values[1:])/255.0 * 0.99) + 0.01\n",
    "    # 신경망에 질의\n",
    "    outputs = n.query(inputs)\n",
    "    # 가장 높은 값의 인덱스는 레이블의 인덱스와 일치\n",
    "    label = np.argmax(outputs)\n",
    "    # print(\"network's answer :\", label)\n",
    "    # 정답 또는 오답을 리스트에 추가\n",
    "    if (label == correct_label):\n",
    "        # 정답인 경우 성적표에 1을 넣음\n",
    "        scorecard.append(1)\n",
    "    else:\n",
    "        # 정답이 아닌 경우 성적표에 0을 넣음\n",
    "        scorecard.append(0)\n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performace =  0.6\n"
     ]
    }
   ],
   "source": [
    "# 정답의 비율인 성적을 계산해 출력\n",
    "scorecard_array = np.asarray(scorecard)\n",
    "print(\"performace = \", scorecard_array.sum() / scorecard_array.size )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MNIST 학습 데이터인 csv 파일을 리스트로 불러오기\n",
    "training_data_file = open('./mnist_train.csv','r')\n",
    "training_data_list = training_data_file.readlines()\n",
    "training_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 신경망 학습시키기\n",
    "\n",
    "# 주기(epoch)란 학습 데이터가 학습을 위해 사용되는 횟수를 의미\n",
    "epochs = 2\n",
    "\n",
    "for e in range(epochs): \n",
    "    # 학습 데이터 모음 내의 모든 레코드 탐색\n",
    "    for record in training_data_list:\n",
    "        # 레코드를 쉼표에 의해 분리\n",
    "        all_values = record.split(',')\n",
    "        # 입력 값의 범위와 값 조정\n",
    "        inputs = (np.asfarray(all_values[1:])/ 255.0 * 0.99) + 0.01\n",
    "        # 결과값 생성 (실제 값인 0.99 외에는 모두 0.01)\n",
    "        targets = np.zeros(output_nodes) + 0.01\n",
    "        # all_values[0]은 이 레코드에 대한 결과값\n",
    "        targets[int(all_values[0])] = 0.99\n",
    "        n.train(inputs, targets)\n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 테스트 데이터 불러오기\n",
    "test_data_file = open('./mnist_test.csv','r')\n",
    "test_data_list = test_data_file.readlines()\n",
    "test_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 신경망 테스트\n",
    "\n",
    "# 신경망의 성능의 지표가 되는 성적표를 아무 값도 가지지 않도록 초기화\n",
    "scorecard = []\n",
    "\n",
    "# 테스트 데이터 모음 내의 모든 레코드 탑색\n",
    "\n",
    "for record in test_data_list:\n",
    "    # 레코드를 쉼표에 의해 분리\n",
    "    all_values = record.split(',')\n",
    "    # 정답은 첫 번째 값\n",
    "    correct_label = int(all_values[0])\n",
    "    # print(\"correct lable\", correct_label)\n",
    "    # 입력 값의 범위와 값 조정\n",
    "    inputs = (np.asfarray(all_values[1:])/255.0 * 0.99) + 0.01\n",
    "    # 신경망에 질의\n",
    "    outputs = n.query(inputs)\n",
    "    # 가장 높은 값의 인덱스는 레이블의 인덱스와 일치\n",
    "    label = np.argmax(outputs)\n",
    "    # print(\"network's answer :\", label)\n",
    "    # 정답 또는 오답을 리스트에 추가\n",
    "    if (label == correct_label):\n",
    "        # 정답인 경우 성적표에 1을 넣음\n",
    "        scorecard.append(1)\n",
    "    else:\n",
    "        # 정답이 아닌 경우 성적표에 0을 넣음\n",
    "        scorecard.append(0)\n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performace =  0.9511\n"
     ]
    }
   ],
   "source": [
    "# 정답의 비율인 성적을 계산해 출력\n",
    "scorecard_array = np.asarray(scorecard)\n",
    "print(\"performace = \", scorecard_array.sum() / scorecard_array.size )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
